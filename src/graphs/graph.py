from datetime import datetime
from langgraph.graph import StateGraph, END
from langchain_core.runnables import RunnableConfig
from langgraph.runtime import Runtime
from coze_coding_utils.runtime_ctx.context import Context

from graphs.state import (
    GlobalState,
    GraphInput,
    GraphOutput,
    LoadMemoryWrapInput, LoadMemoryWrapOutput,
    HomeworkCheckWrapInput, HomeworkCheckWrapOutput,
    ActiveCareWrapInput, ActiveCareWrapOutput,
    SpeakingPracticeWrapInput, SpeakingPracticeWrapOutput,
    RealtimeConversationWrapInput, RealtimeConversationWrapOutput,
    VoiceSynthesisWrapInput, VoiceSynthesisWrapOutput,
    SaveMemoryWrapInput, SaveMemoryWrapOutput,
    LongTermMemoryInput, LongTermMemoryOutput,
    HomeworkCheckInput, HomeworkCheckOutput,
    ActiveCareInput, ActiveCareOutput,
    SpeakingPracticeInput, SpeakingPracticeOutput,
    RealtimeConversationInput, RealtimeConversationOutput,
    VoiceSynthesisInput, VoiceSynthesisOutput,
    RouteDecisionInput,
    RealtimeCallInput, RealtimeCallOutput
)
from graphs.node import (
    long_term_memory_node,
    homework_check_node,
    active_care_node,
    speaking_practice_node,
    realtime_conversation_node,
    voice_synthesis_node,
    route_decision,
    realtime_call_fast_node
)


# ============== åŒ…è£…å‡½æ•°ï¼šä½¿ç”¨ç‹¬ç«‹çš„Input/Outputç±»å‹ ==============
def wrap_load_memory(
    state: LoadMemoryWrapInput,
    config: RunnableConfig,
    runtime: Runtime[Context]
) -> LoadMemoryWrapOutput:
    """åŠ è½½é•¿æœŸè®°å¿†ï¼ˆæ”¯æŒè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰"""
    ctx = runtime.context
    
    node_input = LongTermMemoryInput(
        child_id=state.child_id,
        action_type="load"
    )
    node_output: LongTermMemoryOutput = long_term_memory_node(node_input, config, runtime)
    
    # å¦‚æœæœ‰éŸ³é¢‘è¾“å…¥ä½†æ²¡æœ‰æ–‡æœ¬ï¼Œè‡ªåŠ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«
    recognized_text = state.user_input_text
    if state.user_input_audio and not state.user_input_text:
        try:
            from coze_coding_dev_sdk import ASRClient
            asr_client = ASRClient(ctx=ctx)
            text, _ = asr_client.recognize(
                uid=f"{state.child_name}_{datetime.now().strftime('%Y%m%d%H%M%S')}",
                url=state.user_input_audio.url
            )
            recognized_text = text
            print(f"ğŸ¤ è¯­éŸ³è¯†åˆ«æˆåŠŸï¼š{recognized_text}")
        except Exception as e:
            print(f"âš ï¸ è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼š{e}")
            recognized_text = state.user_input_text
    
    return LoadMemoryWrapOutput(
        child_id=state.child_id,
        child_name=state.child_name,
        child_age=state.child_age,
        child_interests=state.child_interests,
        trigger_type=state.trigger_type,
        user_input_text=recognized_text,  # ä½¿ç”¨è¯†åˆ«åçš„æ–‡æœ¬
        user_input_audio=state.user_input_audio,
        homework_list=state.homework_list,
        conversation_history=node_output.conversation_history,
        learning_progress=node_output.learning_progress,
        speaking_practice_count=node_output.speaking_practice_count,
        current_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )


def wrap_homework_check(
    state: HomeworkCheckWrapInput, 
    config: RunnableConfig, 
    runtime: Runtime[Context]
) -> HomeworkCheckWrapOutput:
    """ä½œä¸šæ£€æŸ¥"""
    node_input = HomeworkCheckInput(
        homework_list=state.homework_list,
        current_time=state.current_time,
        child_id=state.child_id
    )
    node_output: HomeworkCheckOutput = homework_check_node(node_input, config, runtime)
    
    return HomeworkCheckWrapOutput(
        homework_status=node_output.homework_status,
        need_remind=node_output.need_remind,
        ai_response=node_output.remind_message
    )


def wrap_active_care(
    state: ActiveCareWrapInput, 
    config: RunnableConfig, 
    runtime: Runtime[Context]
) -> ActiveCareWrapOutput:
    """ä¸»åŠ¨å…³å¿ƒ"""
    node_input = ActiveCareInput(
        child_name=state.child_name,
        child_age=state.child_age,
        child_interests=state.child_interests,
        conversation_history=state.conversation_history,
        current_time=state.current_time
    )
    node_output: ActiveCareOutput = active_care_node(node_input, config, runtime)
    
    return ActiveCareWrapOutput(ai_response=node_output.care_message)


def wrap_speaking_practice(
    state: SpeakingPracticeWrapInput, 
    config: RunnableConfig, 
    runtime: Runtime[Context]
) -> SpeakingPracticeWrapOutput:
    """å£è¯­ç»ƒä¹ """
    node_input = SpeakingPracticeInput(
        user_input_audio=state.user_input_audio,
        user_input_text=state.user_input_text,
        child_name=state.child_name,
        child_age=state.child_age,
        conversation_history=state.conversation_history,
        practice_topic=""
    )
    node_output: SpeakingPracticeOutput = speaking_practice_node(node_input, config, runtime)
    
    return SpeakingPracticeWrapOutput(
        recognized_text=node_output.recognized_text,
        ai_response=node_output.feedback,
        speaking_practice_count=node_output.practice_count
    )


def wrap_realtime_conversation(
    state: RealtimeConversationWrapInput, 
    config: RunnableConfig, 
    runtime: Runtime[Context]
) -> RealtimeConversationWrapOutput:
    """å®æ—¶å¯¹è¯ï¼ˆæ”¯æŒä½œä¸šçŠ¶æ€è‡ªåŠ¨æ›´æ–°ï¼‰"""
    import json
    from graphs.memory_store import MemoryStore
    from langchain_core.messages import HumanMessage, SystemMessage
    
    # å¦‚æœæœ‰éŸ³é¢‘ä½†æ²¡æœ‰æ–‡æœ¬ï¼Œå…ˆè¯†åˆ«
    user_text = state.user_input_text
    from graphs.node import realtime_conversation_node
    from coze_coding_dev_sdk import ASRClient, LLMClient
    
    # è·å–æœ‰æ•ˆä½œä¸šä¿¡æ¯ï¼Œç”¨äºAIåˆ¤æ–­ä½œä¸šå®Œæˆæƒ…å†µ
    memory_store = MemoryStore.get_instance()
    valid_homework = memory_store.get_valid_homework(state.child_id)
    homework_info = ""
    if valid_homework:
        subjects = [hw.get("subject", "") for hw in valid_homework]
        homework_info = f"æœªå®Œæˆä½œä¸šï¼š{', '.join(subjects)}"
    else:
        homework_info = "æ‰€æœ‰ä½œä¸šå·²å®Œæˆ"
    
    node_input = RealtimeConversationInput(
        user_input_text=user_text,
        child_name=state.child_name,
        child_age=state.child_age,
        conversation_history=state.conversation_history,
        context_info=f"ä½œä¸šçŠ¶æ€ï¼š{state.homework_status}ï¼Œ{homework_info}"
    )
    node_output: RealtimeConversationOutput = realtime_conversation_node(node_input, config, runtime)
    
    ai_response_text = node_output.ai_response
    
    # ä½¿ç”¨ç¬¬äºŒä¸ªLLMè°ƒç”¨æ¥åˆ¤æ–­æ˜¯å¦æåˆ°äº†ä½œä¸šå®Œæˆ
    # è¿™æ ·æ›´å¯é ï¼Œä¸ä¾èµ–ä¸»å¯¹è¯LLMçš„æ ¼å¼è¾“å‡º
    if valid_homework:
        subjects_str = "ã€".join([hw.get("subject", "") for hw in valid_homework])
        
        # ä½¿ç”¨LLMåˆ¤æ–­å¯¹è¯ä¸­æ˜¯å¦æåˆ°ä½œä¸šå®Œæˆ
        judgment_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä½œä¸šçŠ¶æ€è¯†åˆ«åŠ©æ‰‹ã€‚è¯·åˆ†æä»¥ä¸‹å¯¹è¯ï¼Œåˆ¤æ–­å­©å­æ˜¯å¦ç¡®è®¤å®Œæˆäº†æŸä¸ªä½œä¸šã€‚

å­©å­çš„å¹´é¾„ï¼š{state.child_age}å²
å­©å­è¯´ï¼š{user_text}
AIå›å¤ï¼š{ai_response_text}

æœªå®Œæˆçš„ä½œä¸šåˆ—è¡¨ï¼š{subjects_str}

è¯·åˆ¤æ–­ï¼š
1. å­©å­æ˜¯å¦æ˜ç¡®è¡¨ç¤ºå®Œæˆäº†æŸä¸ªä½œä¸šï¼Ÿ
2. å¦‚æœå®Œæˆäº†ï¼Œæ˜¯å“ªä¸ªå­¦ç§‘çš„ä½œä¸šï¼Ÿ

åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼š
{{"homework_completed": true/false, "subject": "å­¦ç§‘åç§°æˆ–ç©ºå­—ç¬¦ä¸²", "confirmed": true/false}}

è§„åˆ™ï¼š
- homework_completed: å¦‚æœå­©å­æ˜ç¡®è¯´"åšå®Œäº†"ã€"å®Œæˆäº†"ç­‰ï¼Œè®¾ä¸ºtrueï¼Œå¦åˆ™false
- subject: æå–å­¦ç§‘åç§°ï¼ˆå¦‚"æ•°å­¦"ã€"è¯­æ–‡"ã€"è‹±è¯­"ï¼‰ï¼Œå¦‚æœä¸ç¡®å®šåˆ™ä¸ºç©ºå­—ç¬¦ä¸²
- confirmed: å¦‚æœå­©å­ç¡®è®¤å®Œæˆï¼ˆå¦‚"æ˜¯çš„"ã€"çœŸçš„åšå®Œäº†"ç­‰ï¼‰ï¼Œè®¾ä¸ºtrueï¼Œå¦åˆ™false"""
        
        try:
            client = LLMClient(ctx=runtime.context)
            messages = [HumanMessage(content=judgment_prompt)]
            response = client.invoke(messages=messages, model="doubao-seed-1-8-251228", temperature=0.3)
            
            # è§£æLLMçš„åˆ¤æ–­ç»“æœ
            judgment_text = str(response.content).strip()
            # æå–JSONéƒ¨åˆ†
            if "{" in judgment_text and "}" in judgment_text:
                json_start = judgment_text.find("{")
                json_end = judgment_text.rfind("}") + 1
                json_str = judgment_text[json_start:json_end]
                
                homework_completed_info = json.loads(json_str)
                
                # å¦‚æœç¡®è®¤ä½œä¸šå®Œæˆï¼Œæ›´æ–°ä½œä¸šçŠ¶æ€
                if homework_completed_info.get("homework_completed", False) and homework_completed_info.get("confirmed", False):
                    subject = homework_completed_info.get("subject", "")
                    if subject:
                        # æŸ¥æ‰¾åŒ¹é…çš„ä½œä¸šå¹¶æ ‡è®°ä¸ºå®Œæˆ
                        for hw in valid_homework:
                            if subject in hw.get("subject", ""):
                                memory_store.complete_homework(state.child_id, hw["id"])
                                print(f"âœ… è‡ªåŠ¨æ›´æ–°ä½œä¸šçŠ¶æ€ï¼š{subject} ä½œä¸šæ ‡è®°ä¸ºå·²å®Œæˆ")
                                break
        except Exception as e:
            print(f"âš ï¸  ä½œä¸šå®Œæˆåˆ¤æ–­å¤±è´¥: {e}")
    
    return RealtimeConversationWrapOutput(ai_response=ai_response_text)


def wrap_voice_synthesis(
    state: VoiceSynthesisWrapInput, 
    config: RunnableConfig, 
    runtime: Runtime[Context]
) -> VoiceSynthesisWrapOutput:
    """è¯­éŸ³åˆæˆ"""
    node_input = VoiceSynthesisInput(
        text=state.ai_response,
        child_age=state.child_age,
        voice_type="child" if state.child_age <= 12 else "normal"
    )
    node_output: VoiceSynthesisOutput = voice_synthesis_node(node_input, config, runtime)
    
    return VoiceSynthesisWrapOutput(ai_response_audio=node_output.audio_url)


def wrap_save_memory(
    state: SaveMemoryWrapInput, 
    config: RunnableConfig, 
    runtime: Runtime[Context]
) -> SaveMemoryWrapOutput:
    """ä¿å­˜é•¿æœŸè®°å¿†"""
    from graphs.memory_store import MemoryStore
    
    memory_store = MemoryStore.get_instance()
    
    # æ„å»ºå¯¹è¯è®°å½•
    conversation_record = {
        "role": "user",
        "content": state.user_input_text or state.recognized_text,
        "type": state.trigger_type
    }
    memory_store.add_conversation(state.child_id, conversation_record)
    
    # æ·»åŠ AIå›å¤
    if state.ai_response:
        ai_record = {
            "role": "assistant",
            "content": state.ai_response,
            "type": state.trigger_type
        }
        memory_store.add_conversation(state.child_id, ai_record)
    
    # æ›´æ–°å­¦ä¹ è¿›åº¦
    if state.trigger_type == "practice":
        memory_store.update_learning_progress(state.child_id, {
            "speaking_practice_count": state.speaking_practice_count,
            "last_practice_time": state.current_time
        })
    
    return SaveMemoryWrapOutput(saved=True)


# ============== å®æ—¶é€šè¯å¿«é€ŸåŒ…è£…å‡½æ•° ==============
def wrap_realtime_call(
    state: LoadMemoryWrapInput,
    config: RunnableConfig,
    runtime: Runtime[Context]
) -> GraphOutput:
    """
    å®æ—¶é€šè¯å¿«é€Ÿè·¯å¾„
    ç›´æ¥æ•´åˆASR+LLM+TTSï¼Œæœ€å°åŒ–å»¶è¿Ÿ
    """
    # æ„å»ºè¾“å…¥ - ä½¿ç”¨RealtimeCallInput
    node_input = RealtimeCallInput(
        user_input_text=state.user_input_text,
        user_input_audio=state.user_input_audio,  # ç›´æ¥ä¼ é€’éŸ³é¢‘
        child_name=state.child_name,
        child_age=state.child_age,
        child_id=state.child_id
    )

    # è°ƒç”¨å¿«é€ŸèŠ‚ç‚¹
    result: RealtimeCallOutput = realtime_call_fast_node(node_input, config, runtime)

    # å¼‚æ­¥ä¿å­˜è®°å¿†ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
    try:
        from graphs.memory_store import MemoryStore
        memory_store = MemoryStore.get_instance()

        # ä¿å­˜å¯¹è¯è®°å½•
        if result.recognized_text:
            memory_store.add_conversation(state.child_id, {
                "role": "user",
                "content": result.recognized_text,
                "type": "realtime_call",
                "timestamp": datetime.now().isoformat()
            })

        if result.ai_response:
            memory_store.add_conversation(state.child_id, {
                "role": "assistant",
                "content": result.ai_response,
                "type": "realtime_call",
                "timestamp": datetime.now().isoformat()
            })
    except Exception as e:
        print(f"âš ï¸ å¼‚æ­¥ä¿å­˜è®°å¿†å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰ï¼š{e}")

    return GraphOutput(
        ai_response=result.ai_response,
        ai_response_audio=result.ai_response_audio,
        trigger_type="realtime_call",
        homework_status="",
        speaking_practice_count=0
    )





# ============== åˆ›å»ºä¸»å›¾ ==============
builder = StateGraph(GlobalState, input_schema=GraphInput, output_schema=GraphOutput)

# æ·»åŠ èŠ‚ç‚¹ï¼ˆä½¿ç”¨åŒ…è£…å‡½æ•°ï¼‰
builder.add_node("load_memory", wrap_load_memory)
builder.add_node("homework_check", wrap_homework_check)
builder.add_node("active_care", wrap_active_care, metadata={
    "type": "agent",
    "llm_cfg": "config/active_care_llm_cfg.json"
})
builder.add_node("speaking_practice", wrap_speaking_practice)
builder.add_node("realtime_conversation", wrap_realtime_conversation, metadata={
    "type": "agent",
    "llm_cfg": "config/realtime_conversation_llm_cfg.json"
})
builder.add_node("realtime_call", wrap_realtime_call)  # å®æ—¶é€šè¯å¿«é€ŸèŠ‚ç‚¹
builder.add_node("voice_synthesis", wrap_voice_synthesis)
builder.add_node("save_memory", wrap_save_memory)

# è®¾ç½®å…¥å£ç‚¹
builder.set_entry_point("load_memory")

# æ·»åŠ æ¡ä»¶åˆ†æ”¯
builder.add_conditional_edges(
    source="load_memory",
    path=route_decision,
    path_map={
        "ä¸»åŠ¨å…³å¿ƒ": "active_care",
        "ä½œä¸šæé†’": "homework_check",
        "å£è¯­ç»ƒä¹ ": "speaking_practice",
        "å®æ—¶å¯¹è¯": "realtime_conversation",
        "å®æ—¶é€šè¯": "realtime_call"
    }
)

# æ·»åŠ åç»­è¾¹ - æ‰€æœ‰å¤„ç†åˆ†æ”¯éƒ½æ±‡èšåˆ°è¯­éŸ³åˆæˆ
builder.add_edge("active_care", "voice_synthesis")
builder.add_edge("homework_check", "voice_synthesis")
builder.add_edge("speaking_practice", "voice_synthesis")
builder.add_edge("realtime_conversation", "voice_synthesis")

# è¯­éŸ³åˆæˆåä¿å­˜è®°å¿†
builder.add_edge("voice_synthesis", "save_memory")

# ç»“æŸ
builder.add_edge("save_memory", END)

# ç¼–è¯‘å›¾
main_graph = builder.compile()
